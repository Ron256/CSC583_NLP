{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Ronaldlee Ejalu**\n",
        "\n",
        "**CSC 583**\n",
        "\n",
        "**HW#5** "
      ],
      "metadata": {
        "id": "Ch-pAIzgN05v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 11"
      ],
      "metadata": {
        "id": "QztsZu8Vfbka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1"
      ],
      "metadata": {
        "id": "X2El5Mm8fkLe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv8_Q4aIY3Y-",
        "outputId": "358766d0-f914-41d7-e149-1c7117b0ecc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5b1c22c890>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import itertools\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
        "\n",
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "data = []\n",
        "\"\"\"\n",
        "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
        "    context = (\n",
        "        [raw_text[i - j - 1] for j in range(CONTEXT_SIZE)]\n",
        "        + [raw_text[i + j + 1] for j in range(CONTEXT_SIZE)]\n",
        "    )\n",
        "\"\"\"\n",
        "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
        "    context = (\n",
        "        [raw_text[i - CONTEXT_SIZE], raw_text[i - (CONTEXT_SIZE - 1)], \\\n",
        "              raw_text[i + (CONTEXT_SIZE - 1)], raw_text[i + CONTEXT_SIZE]]\n",
        "    )\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "print(data[:5])\n",
        "\n",
        "class CBOW(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "      super(CBOW, self).__init__()\n",
        "      self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "      self.linear1 = nn.Linear(embedding_dim, 128) # hidden layer\n",
        "      self.activation_function1 = nn.ReLU() # activation layer\n",
        "      self.linear2 = nn.Linear(128, vocab_size) # another hidden layer\n",
        "      # Applies the log(Softmax(x)) function to an n-dimensional input Tensor.\n",
        "      self.activation_function2 = nn.LogSoftmax(dim = -1) # activation layer\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
        "      out = self.linear1(embeds)\n",
        "      out = self.activation_function1(out)\n",
        "      out = self.linear2(out)\n",
        "      out = self.activation_function2(out)\n",
        "      return out\n",
        "\n",
        "# Create your model and train. Here are some functions to help you make\n",
        "# the data ready for use by your module.\n",
        "\n",
        "def make_context_vector(context, word_to_ix):\n",
        "  idxs = [word_to_ix[w] for w in context]\n",
        "  return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "make_context_vector(data[0][0], word_to_ix)  # example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGqAh9_BZJ4j",
        "outputId": "e69f360f-0997-456c-d8c7-36a1557d78cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([15, 24,  5, 44])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "EMBEDDING_DIM = 10\n",
        "print('The vocabulary size is %d.' %vocab_size)\n",
        "model = CBOW(vocab_size, EMBEDDING_DIM)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for context, target in data:\n",
        "\n",
        "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
        "        # into integer indices and wrap them in tensors)\n",
        "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
        "\n",
        "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
        "        # new instance, you need to zero out the gradients from the old\n",
        "        # instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 3. Run the forward pass, getting log probabilities over next\n",
        "        # words\n",
        "        log_probs = model(context_idxs)\n",
        "\n",
        "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
        "        # word wrapped in a tensor)\n",
        "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "\n",
        "        # Step 5. Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "        total_loss += loss.item()\n",
        "    losses.append(total_loss)\n",
        "print(losses)  # The loss decreased every iteration over the training data!\n",
        "\n",
        "# To get the embedding of a particular word, e.g. \"beauty\"\n",
        "print(\"The embedding vector for 'procecess' is:\")\n",
        "print(model.embeddings.weight[word_to_ix[\"processes\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E1XRdqPZp9F",
        "outputId": "c32396b6-9dc0-49d9-d2a5-3e29a9d1b961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary size is 49.\n",
            "[230.22597670555115, 225.9807469844818, 221.90891313552856, 218.00054550170898, 214.24484992027283, 210.63149189949036, 207.1489531993866, 203.79080986976624, 200.54813313484192, 197.41282880306244]\n",
            "The embedding vector for 'procecess' is:\n",
            "tensor([ 2.4161,  1.0208, -0.4396, -1.7347, -1.2398,  1.5813, -1.1160,  0.7683,\n",
            "        -0.5879,  2.1180], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_idx = word_to_ix['processes']\n",
        "processes_tensor = torch.tensor(process_idx, dtype=torch.long)\n",
        "process_similar = {}\n",
        "cos = nn.CosineSimilarity(dim=0)\n",
        "for i in range(len(data)):\n",
        "  item = data[i][0]\n",
        "  for num in range(len(item)):\n",
        "    word_str = 'processes' + '-' + item[num] \n",
        "    if item[num] == 'processes':\n",
        "      pass\n",
        "    else:\n",
        "      output = cos(model.embeddings.weight[word_to_ix[\"processes\"]], model.embeddings.weight[word_to_ix[item[num]]])\n",
        "      res = output.detach().numpy()\n",
        "      ts = res.tobytes() \n",
        "      arr = np.frombuffer(ts, dtype=res.dtype) # we change to an array\n",
        "      process_similar[word_str] =  arr[0]"
      ],
      "metadata": {
        "id": "aTJ-ha26lUL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the dictionary into pandas data frame\n",
        "df_cosineSimProcesses = pd.DataFrame(process_similar.items(), columns=['similar-words', 'cosine_value'])"
      ],
      "metadata": {
        "id": "83EejyoT0JuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the data frame\n",
        "df_cosineSimProcesses_Sorted = df_cosineSimProcesses.sort_values(by='cosine_value', ascending=False)\n",
        "print(\"The top three words that are closest to 'processes' by cosine similarity:\")\n",
        "df_cosineSimProcesses_Sorted.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "XFCbhu_C0p0E",
        "outputId": "45654dfc-b7c0-4272-b65a-994df13a0970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top three words that are closest to 'processes' by cosine similarity:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        similar-words  cosine_value\n",
              "42  processes-conjure      0.564105\n",
              "18     processes-they      0.469889\n",
              "45     processes-with      0.415042"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a5abd6c-1dc9-49f3-bf25-6f52d0364205\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similar-words</th>\n",
              "      <th>cosine_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>processes-conjure</td>\n",
              "      <td>0.564105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>processes-they</td>\n",
              "      <td>0.469889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>processes-with</td>\n",
              "      <td>0.415042</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a5abd6c-1dc9-49f3-bf25-6f52d0364205')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a5abd6c-1dc9-49f3-bf25-6f52d0364205 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a5abd6c-1dc9-49f3-bf25-6f52d0364205');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 11"
      ],
      "metadata": {
        "id": "-ukxHg-_6gC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "94FEEJ_b6kwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20fbc717-29fd-4818-b9e3-7f7efb3fd0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /gdrive/MyDrive/CSC583"
      ],
      "metadata": {
        "id": "GGKce0hG6qzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08ceba0-5286-400e-effc-d5cd043cbef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/CSC583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directoryPath_pos = '/gdrive/MyDrive/CSC583/data/homework5/txt_sentoken/pos/pos'"
      ],
      "metadata": {
        "id": "eP28qxZK6rzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('There are %d files in the pos directory.' %len(os.listdir(directoryPath_pos)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nGX3dUc-m4h",
        "outputId": "3f7059e9-aa4d-4517-fdcc-48408e8abad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1000 files in the pos directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_L = ['cv199_9629.txt', 'cv261_10954.txt', 'cv315_11629.txt', \\\n",
        "          'cv368_10466.txt', 'cv401_12605.txt', 'cv453_10379.txt', \\\n",
        "          'cv519_14661.txt', 'cv729_10154.txt', 'cv782_19526.txt', 'cv900_10331.txt']"
      ],
      "metadata": {
        "id": "r8AUnow01hX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read all the reviews files and store them in a list"
      ],
      "metadata": {
        "id": "R6KKT84DqhYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_L = []\n",
        "for num in range(len(file_L)):\n",
        "  fileNamePath = \"data/homework5/txt_sentoken/pos/pos/\" + file_L[num]\n",
        "  with open(fileNamePath, 'r',  encoding = 'ISO-8859-1') as sampleFile:\n",
        "    fileContents = sampleFile.read()\n",
        "    # normalize all words to lower case\n",
        "    reviews_L.append(fileContents.lower())"
      ],
      "metadata": {
        "id": "Nvr6Pl6kjYfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(reviews_L)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XZ3Dh6zCe-n",
        "outputId": "6f1ddc39-c653-444e-81b9-c9397078adc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def populateWordFrequency(filtered_reviews_200):\n",
        "  \"\"\"Function that a list afte tokening the text, processing the \n",
        "  individual words and then derives the frequency of the words \n",
        "  \"\"\"\n",
        "  # reset the dictionary\n",
        "  wordFrequency = {}\n",
        "\n",
        "  # populate the dictionary with the frequecny of words\n",
        "  for i in range(len(filtered_reviews_200)):\n",
        "    item = filtered_reviews_200[i]\n",
        "    if item in wordFrequency:\n",
        "      wordFrequency[item] += 1\n",
        "    else:\n",
        "      wordFrequency[item] = 1\n",
        "\n",
        "  # sort the dictionary and create a list of tuples\n",
        "  wordSorted = sorted((value, key) for (key, value) in wordFrequency.items())\n",
        "  sortedWordFrequency = [(key, value) for (value, key) in wordSorted]\n",
        "\n",
        "  # create a data frame\n",
        "  df = pd.DataFrame(sortedWordFrequency, columns=['Word', 'Freq'])\n",
        "  # sort the data frame in descending order\n",
        "  df.sort_values(by=['Freq'], ascending=False, inplace=True)\n",
        "  # reset the index\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  df.index = np.arange(1, len(df) + 1)\n",
        "  df.head()\n",
        "  \n",
        "  #return df.head(n).values.tolist()\n",
        "  return df.values.tolist()"
      ],
      "metadata": {
        "id": "_jU0SkHz2_-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter stop words with the nltk\n",
        "stopWords = set(stopwords.words('english'))\n",
        "# create a tokenizer based on a regular expression.\n",
        "# '[a-zA-Z0-9]+' captures all alphanumeric characters\n",
        "tokenizer = RegexpTokenizer(r\"[a-zA-Z0-9]+\")\n",
        "filtered_L = [] # list that stores all the reviews of the different tokens\n",
        "for i in range(len(reviews_L)):\n",
        "  filtered_reviews = []\n",
        "  tokenized_review = tokenizer.tokenize(reviews_L[i])\n",
        "  for tokenized_w in tokenized_review:\n",
        "    if tokenized_w not in stopWords:\n",
        "      # add the filtered tokens to a list\n",
        "      filtered_reviews.append(tokenized_w)\n",
        "  # take the first 200 words in the order of sequence and them to the list of list\n",
        "  filtered_L.append(filtered_reviews[0:200])\n",
        "#len(filtered_L[1])\n",
        "# merge all the reviews together\n",
        "merged_reviews = list(itertools.chain.from_iterable(filtered_L))\n",
        "print('There are %d tokens in the merged reviews.' %len(merged_reviews))\n",
        "#most_frequent_words_L = [] # list of most frequent words for review\n",
        "most_frequent_tokens = populateWordFrequency(merged_reviews)\n",
        "most_frequent_149_Words_L = []\n",
        "for i in range(len(most_frequent_tokens[:149])):\n",
        "  # populate the list of the reviews with the tokens of the frequent words as per requirements\n",
        "  most_frequent_149_Words_L.append(most_frequent_tokens[i][0])\n",
        "\n",
        "vocab_reviews = set(most_frequent_149_Words_L)\n",
        "# add the 'unk' to make the vocabulary size 150\n",
        "vocab_reviews.add('<unk>')"
      ],
      "metadata": {
        "id": "5D3dZsIOqSL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101fbf63-9870-467c-8416-4d122d72b3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2000 tokens in the merged reviews.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create the lookup tables** (word -> index and index -> word)"
      ],
      "metadata": {
        "id": "nsg6E3p0U3uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab_reviews)}\n",
        "index_to_word = {i: word for (i, word) in enumerate(vocab_reviews)}"
      ],
      "metadata": {
        "id": "Xu_1umbzDrst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_L = [] # initialize a list of data \n",
        "for num in range(len(filtered_L)):\n",
        "  data=[]\n",
        "  for i in range(CONTEXT_SIZE, len(filtered_L[num]) - CONTEXT_SIZE):\n",
        "    raw_text = filtered_L[num]\n",
        "    context = (\n",
        "        [raw_text[i - CONTEXT_SIZE], raw_text[i - (CONTEXT_SIZE - 1)], \\\n",
        "              raw_text[i + (CONTEXT_SIZE - 1)], raw_text[i + CONTEXT_SIZE]]\n",
        "    )\n",
        "    #print(context)\n",
        "    target = raw_text[i]\n",
        "    # ignore the case where the target word is <unk>\n",
        "    # ignore the case where either left or right side in the Context turns out to be made of just <unk>\n",
        "    if target == '<unk>' or context[0] == '<unk>' or context[2] == '<unk>':\n",
        "      pass\n",
        "    else:\n",
        "      data.append((context, target))\n",
        "    #print(context, target)\n",
        "  # add the data to the list of data \n",
        "  data_L.append(data)"
      ],
      "metadata": {
        "id": "DbTcYIRbarON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the data by combining the list of the data set\n",
        "data = list(itertools.chain.from_iterable(data_L))"
      ],
      "metadata": {
        "id": "-L0mLg58r-_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "      super(CBOW, self).__init__()\n",
        "      self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "      #self.linear = nn.Linear(embedding_dim, 128) # hidden layer\n",
        "      #self.activation_function1 = nn.ReLU() # activation layer\n",
        "      #self.linear2 = nn.Linear(128, vocab_size) # another hidden layer\n",
        "      # Applies the log(Softmax(x)) function to an n-dimensional input Tensor.\n",
        "      self.activation_function2 = nn.LogSoftmax(dim = -1) # activation layer\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
        "      #out = self.linear(embeds)\n",
        "      #out = self.activation_function1(out)\n",
        "      #out = self.linear2(out)\n",
        "      out = self.activation_function2(embeds)\n",
        "      return out"
      ],
      "metadata": {
        "id": "SVaYksR6vFFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "EMBEDDING_DIM = 20\n",
        "VOCAB_SIZE = 150\n",
        "\n",
        "model = CBOW(VOCAB_SIZE, EMBEDDING_DIM)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for context, target in data:\n",
        "\n",
        "\n",
        "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
        "        # into integer indices and wrap them in tensors)\n",
        "        #context_idxs = torch.tensor([word_to_ix.get(w, word_to_ix['<unk>']) for w in context if w == '<unk>' pass], dtype=torch.long)\n",
        "        context_idxs = torch.tensor([word_to_ix.get(w, word_to_ix['<unk>']) for w in context if w != '<unk>'], dtype=torch.long)\n",
        "\n",
        "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
        "        # new instance, you need to zero out the gradients from the old\n",
        "        # instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 3. Run the forward pass, getting log probabilities over next\n",
        "        # words\n",
        "        log_probs = model(context_idxs)\n",
        "\n",
        "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
        "        # word wrapped in a tensor)\n",
        "        if word_to_ix.get(target) is None:\n",
        "          pass\n",
        "        else:\n",
        "          #print(log_probs.shape, torch.tensor([word_to_ix[target]], dtype=torch.long).shape)\n",
        "          loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "\n",
        "          # Step 5. Do the backward pass and update the gradient\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "          total_loss += loss.item()\n",
        "    losses.append(total_loss)\n",
        "print(losses)  # The loss decreased every iteration over the training data!\n",
        "\n",
        "# To get the embedding of a particular word, e.g. \"beauty\"\n",
        "#print(\"The embedding vector for 'procecess' is:\")\n",
        "#print(model.embeddings.weight[word_to_ix[\"processes\"]])"
      ],
      "metadata": {
        "id": "WTXWWYQ2wAVb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "784eb411-5d97-44d8-af17-a3d910575b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-ee02ded0be91>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0;31m#print(log_probs.shape, torch.tensor([word_to_ix[target]], dtype=torch.long).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0;31m# Step 5. Do the backward pass and update the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2704\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target 94 is out of bounds."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, show the embedding made for these words below.  Then find the top 3 most similar words (measured by cosine similarity) for each word (but not including itself), for both context sizes, and write your comments in the report."
      ],
      "metadata": {
        "id": "jHNLOux0Fe5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. titanic"
      ],
      "metadata": {
        "id": "VKgdpA7lFjbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deriveCosineSim(word):\n",
        "  \"\"\"Function that derives the cosine similarity of any word\"\"\"\n",
        "  process_idx = word_to_ix[word]\n",
        "  processes_tensor = torch.tensor(process_idx, dtype=torch.long)\n",
        "  process_similar = {}\n",
        "  cos = nn.CosineSimilarity(dim=0)\n",
        "  for i in range(len(data)):\n",
        "    item = data[i][0]\n",
        "    for num in range(len(item)):\n",
        "      word_str = word + '-' + item[num]\n",
        "      if item[num] == word:\n",
        "        pass\n",
        "      else:\n",
        "        output = cos(model.embeddings.weight[word_to_ix[word]], model.embeddings.weight[word_to_ix.get(item[num], word_to_ix['<unk>'])])\n",
        "        res = output.detach().numpy()\n",
        "        ts = res.tobytes()\n",
        "        arr = np.frombuffer(ts, dtype=res.dtype) # we change to an array\n",
        "        process_similar[word_str] =  arr[0]\n",
        "  return process_similar"
      ],
      "metadata": {
        "id": "1TXbI1pyFXPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_processSim = deriveCosineSim('titanic')"
      ],
      "metadata": {
        "id": "SZ9C31PDQTiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the dictionary into pandas data frame\n",
        "df_cosineSimTitanic = pd.DataFrame(titanic_processSim.items(), columns=['similar-words', 'cosine_value'])"
      ],
      "metadata": {
        "id": "B6U4j6Q_Pe0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the data frame\n",
        "df_cosineSimTitanic_Sorted = df_cosineSimTitanic.sort_values(by='cosine_value', ascending=False)\n",
        "print(\"The top three words that are closest to 'titanic' by cosine similarity:\")\n",
        "df_cosineSimTitanic_Sorted.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "cRO5n2fbRECK",
        "outputId": "e1c9f82d-71c1-4105-ba16-c922924a36a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top three words that are closest to 'titanic' by cosine similarity:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      similar-words  cosine_value\n",
              "699  titanic-dreams      0.468602\n",
              "98    titanic-leads      0.461909\n",
              "120     titanic-man      0.418857"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acbd4271-5458-41fc-add0-bf9eb92f001f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similar-words</th>\n",
              "      <th>cosine_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>titanic-dreams</td>\n",
              "      <td>0.468602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>titanic-leads</td>\n",
              "      <td>0.461909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>titanic-man</td>\n",
              "      <td>0.418857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acbd4271-5458-41fc-add0-bf9eb92f001f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acbd4271-5458-41fc-add0-bf9eb92f001f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acbd4271-5458-41fc-add0-bf9eb92f001f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.acting"
      ],
      "metadata": {
        "id": "al5bnxbWRnE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acting_processSim = deriveCosineSim('acting')"
      ],
      "metadata": {
        "id": "Mb0OY7vrRyY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the dictionary into pandas data frame\n",
        "df_cosineSimActing = pd.DataFrame(acting_processSim.items(), columns=['similar-words', 'cosine_value'])"
      ],
      "metadata": {
        "id": "sf9-oXnPSB03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the data frame\n",
        "df_cosineSimActing_Sorted = df_cosineSimActing.sort_values(by='cosine_value', ascending=False)\n",
        "print(\"The top three words that are closest to 'acting' by cosine similarity:\")\n",
        "df_cosineSimActing_Sorted.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "zhnsS323SJ5-",
        "outputId": "0d1e44de-d0a7-4004-bcec-9ae3a80d6efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top three words that are closest to 'acting' by cosine similarity:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       similar-words  cosine_value\n",
              "48       acting-seen      0.573217\n",
              "124  acting-dicaprio      0.572614\n",
              "133       acting-two      0.506357"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0a1a7df-03f1-4a87-86f8-e1644bb9a54d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similar-words</th>\n",
              "      <th>cosine_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>acting-seen</td>\n",
              "      <td>0.573217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>acting-dicaprio</td>\n",
              "      <td>0.572614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>acting-two</td>\n",
              "      <td>0.506357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0a1a7df-03f1-4a87-86f8-e1644bb9a54d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0a1a7df-03f1-4a87-86f8-e1644bb9a54d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0a1a7df-03f1-4a87-86f8-e1644bb9a54d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.great"
      ],
      "metadata": {
        "id": "A0pVL3pbSh0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "great_processSim = deriveCosineSim('great')"
      ],
      "metadata": {
        "id": "ZWeAr-DVSlji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the dictionary into pandas data frame\n",
        "df_cosineSimGreat = pd.DataFrame(great_processSim.items(), columns=['similar-words', 'cosine_value'])"
      ],
      "metadata": {
        "id": "YOzw5b7hT-NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the data frame\n",
        "df_cosineSimGreat_Sorted = df_cosineSimGreat.sort_values(by='cosine_value', ascending=False)\n",
        "print(\"The top three words that are closest to 'great' by cosine similarity:\")\n",
        "df_cosineSimGreat_Sorted.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "tVa9CDsyUItP",
        "outputId": "7723c143-95f8-4b5e-f53d-b63861a39743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top three words that are closest to 'great' by cosine similarity:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       similar-words  cosine_value\n",
              "197  great-explorers      0.484180\n",
              "647     great-lovett      0.451797\n",
              "709    great-complex      0.445936"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f9c7f75-14eb-4774-a522-4d1760aef4c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similar-words</th>\n",
              "      <th>cosine_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>great-explorers</td>\n",
              "      <td>0.484180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>647</th>\n",
              "      <td>great-lovett</td>\n",
              "      <td>0.451797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>great-complex</td>\n",
              "      <td>0.445936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f9c7f75-14eb-4774-a522-4d1760aef4c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f9c7f75-14eb-4774-a522-4d1760aef4c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f9c7f75-14eb-4774-a522-4d1760aef4c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.poor"
      ],
      "metadata": {
        "id": "fqOpcFGpUZ1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poor_processSim = deriveCosineSim('poor')"
      ],
      "metadata": {
        "id": "6n5XattSUpLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the dictionary into pandas data frame\n",
        "df_cosineSimPoor = pd.DataFrame(poor_processSim.items(), columns=['similar-words', 'cosine_value'])"
      ],
      "metadata": {
        "id": "MTAolsa1UyDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the data frame\n",
        "df_cosineSimPoor_Sorted = df_cosineSimPoor.sort_values(by='cosine_value', ascending=False)\n",
        "print(\"The top three words that are closest to 'poor' by cosine similarity:\")\n",
        "df_cosineSimPoor_Sorted.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "UQvgycoHU7Af",
        "outputId": "b15eb9b6-061a-4b8b-f2e8-10fe504f3203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top three words that are closest to 'poor' by cosine similarity:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    similar-words  cosine_value\n",
              "183      poor-far      0.467065\n",
              "353     poor-much      0.460778\n",
              "225      poor-cal      0.448636"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99499d40-9c6b-4fcb-b267-c98460730956\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similar-words</th>\n",
              "      <th>cosine_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>poor-far</td>\n",
              "      <td>0.467065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>poor-much</td>\n",
              "      <td>0.460778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>poor-cal</td>\n",
              "      <td>0.448636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99499d40-9c6b-4fcb-b267-c98460730956')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99499d40-9c6b-4fcb-b267-c98460730956 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99499d40-9c6b-4fcb-b267-c98460730956');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}